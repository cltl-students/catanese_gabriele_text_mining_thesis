{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create annotation data\n",
    "This notebook reads in the original data file that was provided by the client. Then it selects the English customer feedbacks and creates data files for the annotations. These annotation files include:\n",
    "* a .csv file containing just 50 sentences to check the agreement between annotators on a smaller batch\n",
    "* three .csv files containing around 1000 different sentences for each each annotator (this means that the annotated sentences are different between annotators in order to create a bigger dataset for the task)\n",
    "\n",
    "\n",
    "*note: at this stage the output is hidden because it shows private data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('path/to/airlineDataset.csv', sep= ';', encoding='utf-8') # read the complete dataset provided by the client in .csv format\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = df['QST_language'] == 'EN'\n",
    "en_df = df[en]\n",
    "en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13003 13003 13003\n"
     ]
    }
   ],
   "source": [
    "# split the original feedback text into sentences\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\"])\n",
    "nlp.enable_pipe(\"senter\")\n",
    "\n",
    "\n",
    "ids = []  #feedback id\n",
    "feedbacks = []  # sentences\n",
    "n = 0\n",
    "counter = [] # sentence id\n",
    "\n",
    "for i, feedback in zip(en_df['QST_identifier'], en_df['Open_Answer']):\n",
    "    doc = nlp(str(feedback))\n",
    "    for sent in doc.sents:\n",
    "        if len(sent.text) > 1:\n",
    "            ids.append(i)\n",
    "            feedbacks.append(sent.text)\n",
    "            n += 1\n",
    "            counter.append(n)\n",
    "    # we also append an empty line to separate the feedbacks in the annotation file that is going to be generated\n",
    "    ids.append('')\n",
    "    feedbacks.append('')\n",
    "    counter.append('')\n",
    "    # being the original dataset extremely big, I set a limit to 13000 sentences\n",
    "    if len(feedbacks) > 13000:\n",
    "        break\n",
    "        \n",
    "print(len(ids),len(feedbacks),len(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c, n, text in zip(counter, ids,feedbacks):\n",
    "\n",
    "    print(c, n, text)\n",
    "\n",
    "    if c == 54:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save the dataset for the calculation of the IAA with 50 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data file with the first 50 sentences\n",
    "d = {'Sentence_ID' : counter[:68], 'Feedback_ID' : ids[:68], 'Sentence': feedbacks[:68], 'Aspect_Category' : '', 'Sentiment' : '', 'Aspect_Term' : ''}\n",
    "an_data = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "an_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_data.to_csv('path/to/fifty_sents.csv', sep=';', index = False) # saving as .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a .csv file for each annotator with around 1000 sentences to be annotated\n",
    "\n",
    "*note: when extracting the sentences, we put a higher number than 1000 because empty lines are also contained.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'Sentence_ID' : counter[69:1376], 'Feedback_ID' : ids[69:1376], 'Sentence': feedbacks[69:1376], 'Aspect_Category' : '', 'Sentiment' : '', 'Aspect_Term' : ''}\n",
    "an_data1 = pd.DataFrame(data=d1)\n",
    "an_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_data1.to_csv('path/to/annotator1.csv', sep=';', index = False) # dataset for Annotator 1 with 1000 sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we repeat for the other two annotators\n",
    "\n",
    "d2 = {'Sentence_ID' : counter[1377:2677], 'Feedback_ID' : ids[1377:2677], 'Sentence': feedbacks[1377:2677], 'Aspect_Category' : '', 'Sentiment' : '', 'Aspect_Term' : ''}\n",
    "an_data2 = pd.DataFrame(data=d2)\n",
    "an_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_data2.to_csv('path/to/annotator2.csv', sep=';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = {'Sentence_ID' : counter[2678:3985], 'Feedback_ID' : ids[2678:3985], 'Sentence': feedbacks[2678:3985], 'Aspect_Category' : '', 'Sentiment' : '', 'Aspect_Term' : ''}\n",
    "an_data3 = pd.DataFrame(data=d3)\n",
    "an_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_data3.to_csv('path/to/annotator3.csv', sep=';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the notebook."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf3b6d1e18944233f13c9072965d8e73adeff4cfe081eef78aded2d08b1fb14c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
