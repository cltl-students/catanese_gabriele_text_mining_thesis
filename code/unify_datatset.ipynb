{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the annotated sets to create an ABSA complete dataset\n",
    "Script to create the unified set by merging the sets of the three annotators.\\\n",
    "A total of 2495 sentences were annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_category_labels(aspect_category_series):\n",
    "    \"\"\"\"\n",
    "    Funtion to convert the AC labels from letters, \n",
    "    to their corresponding Category names\n",
    "    \"\"\"\"\n",
    "    \n",
    "    aspect_category_series = aspect_category_series.replace(['a'], 'Service')\n",
    "    aspect_category_series = aspect_category_series.replace(['b'], 'Company')\n",
    "    aspect_category_series = aspect_category_series.replace(['c'], 'Staff')\n",
    "    aspect_category_series = aspect_category_series.replace(['d'], 'Price')\n",
    "    aspect_category_series = aspect_category_series.replace(['e'], 'Travel')\n",
    "    aspect_category_series = aspect_category_series.replace(['f'], 'Aircraft equipment')\n",
    "    aspect_category_series = aspect_category_series.replace(['g'], 'Food')\n",
    "    aspect_category_series = aspect_category_series.replace(['h'], 'Safety')\n",
    "    aspect_category_series = aspect_category_series.replace(['i'], 'Boarding')\n",
    "    aspect_category_series = aspect_category_series.replace(['j'], 'Luggage')\n",
    "    aspect_category_series = aspect_category_series.replace(['k'], 'Information')\n",
    "    aspect_category_series = aspect_category_series.replace(['l'], 'Others')\n",
    "    aspect_category_series = aspect_category_series.replace(['m'], 'Multiple')\n",
    "    aspect_category_series = aspect_category_series.replace(['n'], 'NA')\n",
    "\n",
    "    return aspect_category_series\n",
    "\n",
    "def convert_sentiment_labels(sentiment_series):\n",
    "    \"\"\"\"\n",
    "    Funtion to convert the SP labels from letters, \n",
    "    to their corresponding Polarity names\n",
    "    \"\"\"\"\n",
    "    sentiment_series = sentiment_series.replace(['-1'], 'Negative')\n",
    "    sentiment_series = sentiment_series.replace(['1'], 'Positive')\n",
    "    sentiment_series = sentiment_series.replace(['0'], 'Neutral')\n",
    "    sentiment_series = sentiment_series.replace(['2'], 'Mix')\n",
    "\n",
    "    return sentiment_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to the annotated sets by each annotator\n",
    "directory1 = 'path/to/fiftysents_A1.csv'\n",
    "directory2 = 'path/to/fiftysents_A2.csv'\n",
    "directory3 = 'path/to/fiftysents_A3.csv'\n",
    "\n",
    "# read the files\n",
    "df1 = pd.read_csv(directory1, sep=';', header= 0, encoding= 'utf-8')\n",
    "df1 = df1.dropna()\n",
    "df2 = pd.read_csv(directory2, sep=';', header= 0, encoding= 'utf-8')\n",
    "df2 = df2.dropna()\n",
    "df3 = pd.read_csv(directory3, sep=';', header= 0, encoding= 'utf-8')\n",
    "df3 = df3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the colums and append the content to lists to create a merged pandas dataframe\n",
    "\n",
    "txt1 = df1['Sentence'][1:].astype(str)    # we always skip the first line because it contains the header\n",
    "txt2 = df2['Sentence'][1:].astype(str)\n",
    "txt3 = df3['Sentence'][1:].astype(str)\n",
    "\n",
    "as_cat1 = df1['Aspect_Category'][1:].astype(str)\n",
    "as_cat1 = convert_category_labels(as_cat1)\n",
    "\n",
    "\n",
    "as_cat2 = df2['Aspect_Category'][1:].astype(str)\n",
    "as_cat2 = convert_category_labels(as_cat2)\n",
    "\n",
    "\n",
    "as_cat3 = df3['Aspect_Category'][1:].astype(str)\n",
    "as_cat3 = convert_category_labels(as_cat3)\n",
    "\n",
    "\n",
    "s1 = df1['Sentiment'][1:].astype(str)\n",
    "s1 = convert_sentiment_labels(s1)\n",
    "\n",
    "\n",
    "s2 = df2['Sentiment'][1:].astype(str)\n",
    "s2 = convert_sentiment_labels(s2)\n",
    "\n",
    "s3 = df3['Sentiment'][1:].astype(str)\n",
    "s3 = convert_sentiment_labels(s3)\n",
    "\n",
    "txt1 = txt1.append(txt2)\n",
    "txt1 = txt1.append(txt3)\n",
    "\n",
    "as_cat1 = as_cat1.append(as_cat2)\n",
    "as_cat1 = as_cat1.append(as_cat3)\n",
    "\n",
    "\n",
    "s1 = s1.append(s2)\n",
    "s1 = s1.append(s3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new unified dataset through pandas dataframe\n",
    "\n",
    "new = {'Sentence' : txt1, 'Aspect_Category' : as_cat1, 'Sentiment' : s1}\n",
    "new_df = pd.DataFrame(data=new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it to a .csv file with 'utf-8' encoding\n",
    "new_df.to_csv(\"path/to/absa_dataset.csv\", sep=';', index = False, encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
